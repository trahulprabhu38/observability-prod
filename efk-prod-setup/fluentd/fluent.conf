###########################################################################
# Fluentd Configuration - Docker Log Collection â†’ Elasticsearch
###########################################################################

# Collect Docker container logs
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Collect logs via TCP (alternative input)
<source>
  @type tcp
  port 5170
  bind 0.0.0.0
  tag tcp.logs
  <parse>
    @type json
  </parse>
</source>

# Add Docker metadata to logs
<filter docker.**>
  @type docker_metadata
</filter>

# Parse JSON logs from containers
<filter **>
  @type parser
  key_name log
  reserve_data true
  remove_key_name_field false
  emit_invalid_record_to_error false
  <parse>
    @type json
  </parse>
</filter>

# Handle multiline logs (e.g., stack traces)
<filter **>
  @type concat
  key log
  multiline_start_regexp /^\d{4}-\d{2}-\d{2}/
  flush_interval 5s
</filter>

# Send to Elasticsearch
<match **>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix fluentd
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  tag_key @log_name
  flush_interval 5s
  num_threads 2
  reconnect_on_error true
  reload_on_failure true
  reload_connections false

  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_mode interval
    flush_interval 5s
    chunk_limit_size 8M
    total_limit_size 512M
    retry_max_interval 30
    retry_forever true
  </buffer>
</match>
